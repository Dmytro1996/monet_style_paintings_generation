{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bbedd95-84b2-4875-8dbe-8985401a50c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f15d8214-be42-4440-8b4f-4a7ede7eeb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [[[180, 178, 139], [193, 191, 153], [202, 202,...\n",
       "1      [[[15, 36, 17], [66, 87, 70], [93, 111, 97], [...\n",
       "2      [[[178, 196, 206], [190, 208, 218], [199, 217,...\n",
       "3      [[[160, 164, 191], [163, 169, 195], [164, 170,...\n",
       "4      [[[154, 139, 118], [163, 148, 127], [163, 148,...\n",
       "                             ...                        \n",
       "295    [[[105, 112, 156], [99, 106, 152], [95, 103, 1...\n",
       "296    [[[238, 248, 240], [236, 246, 238], [239, 249,...\n",
       "297    [[[130, 139, 154], [75, 87, 99], [53, 66, 72],...\n",
       "298    [[[219, 223, 186], [219, 223, 186], [220, 222,...\n",
       "299    [[[249, 249, 247], [247, 247, 245], [244, 244,...\n",
       "Length: 300, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_list = []\n",
    "dir = 'images/monet_jpg'\n",
    "for image in os.listdir(dir):\n",
    "    images_list.append(np.asarray(Image.open(dir +'/' + image)))\n",
    "images = pd.Series(images_list)\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "511e3aa5-8102-4405-961c-afb23578f6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(images[0]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "181486db-639a-450c-aa94-ecc8a4e9d815",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(np.rot90(images[0], 3)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "82647e9d-0888-45ae-8d91-40ac7cd741b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image.fromarray(np.flip(np.flip(images[0],0), 1)).show()\n",
    "#Image.fromarray(np.flip(images[0],2)).show()\n",
    "Image.fromarray(np.rot90(np.flip(np.flip(images[0],0), 1), 3)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a937c7f0-68bd-489f-a8eb-3a52c4c89334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [[[147, 127, 118], [185, 167, 155], [200, 184,...\n",
       "1       [[[193, 179, 152], [203, 192, 164], [216, 204,...\n",
       "2       [[[114, 87, 10], [121, 94, 17], [113, 87, 10],...\n",
       "3       [[[193, 179, 152], [196, 182, 155], [204, 190,...\n",
       "4       [[[147, 127, 118], [154, 136, 122], [156, 140,...\n",
       "                              ...                        \n",
       "4495    [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "4496    [[[133, 142, 156], [141, 150, 164], [138, 149,...\n",
       "4497    [[[77, 82, 121], [64, 69, 108], [56, 63, 102],...\n",
       "4498    [[[247, 249, 249], [246, 248, 248], [245, 247,...\n",
       "4499    [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n",
       "Length: 4500, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flipped_image_list = []\n",
    "for image in images_list:\n",
    "    flipped_image_list.append(np.flip(image, 0))\n",
    "    flipped_image_list.append(np.flip(image, 1))\n",
    "    flipped_image_list.append(np.flip(np.flip(image, 0), 1))\n",
    "    flipped_image_list.append(np.rot90(image))\n",
    "    flipped_image_list.append(np.rot90(image, 3))\n",
    "    flipped_image_list.append(np.flip(np.rot90(image), 0))\n",
    "    flipped_image_list.append(np.flip(np.rot90(image), 1))\n",
    "    flipped_image_list.append(np.flip(image, -1))\n",
    "    flipped_image_list.append(np.flip(np.flip(image, 0), -1))\n",
    "    flipped_image_list.append(np.flip(np.flip(image, 1), -1))\n",
    "    flipped_image_list.append(np.flip(np.flip(np.flip(image, 0), 1), -1))\n",
    "    flipped_image_list.append(np.flip(np.rot90(image), -1))\n",
    "    flipped_image_list.append(np.flip(np.rot90(image, 3), -1))\n",
    "    flipped_image_list.append(np.flip(np.flip(np.rot90(image), 0), -1))\n",
    "    flipped_image_list.append(np.flip(np.flip(np.rot90(image), 1), -1))\n",
    "flipped_images = pd.Series(flipped_image_list)\n",
    "flipped_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3c277b2e-7830-4bdc-9e37-7ed6b9161492",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(flipped_images[14]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3c018880-16e1-44a3-b5a1-e5796850f376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [[[113, 110, 101], [113, 110, 101], [112, 112,...\n",
       "1       [[[0, 60, 91], [2, 73, 103], [0, 64, 96], [4, ...\n",
       "2       [[[53, 59, 45], [55, 61, 47], [58, 65, 49], [6...\n",
       "3       [[[79, 86, 96], [80, 87, 97], [82, 89, 99], [8...\n",
       "4       [[[131, 173, 195], [130, 172, 194], [129, 171,...\n",
       "                              ...                        \n",
       "4795    [[[144, 124, 123], [144, 124, 123], [146, 125,...\n",
       "4796    [[[49, 62, 70], [53, 66, 74], [56, 69, 77], [5...\n",
       "4797    [[[58, 86, 133], [55, 86, 133], [53, 84, 131],...\n",
       "4798    [[[149, 190, 234], [152, 193, 237], [152, 193,...\n",
       "4799    [[[30, 40, 29], [29, 39, 28], [30, 40, 29], [3...\n",
       "Length: 4800, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_images_list = []\n",
    "dir = 'images/photo_jpg'\n",
    "for image in os.listdir(dir)[0:4800]:\n",
    "    fake_images_list.append(np.asarray(Image.open(dir +'/' + image)))\n",
    "fake_images = pd.Series(fake_images_list)\n",
    "fake_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a1a66721-7258-457c-8e3e-916eed872713",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(fake_images_list[0]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c9a5a684-bd38-4654-b971-3416e731d54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms.v2 import ToTensor, Normalize, Compose, ToDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f347973c-1261-4a66-9e37-79316225161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose([ToDtype(torch.float32, scale=True), Normalize(mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7f56f596-1672-4009-b5bf-1e6c6689100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape = lambda image : image.reshape(3, 256, 256,)\n",
    "train_data = transforms(torch.tensor(pd.concat([images.apply(reshape), flipped_images.apply(reshape)], ignore_index = True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ad4a5c1e-9d37-4cce-ab91-daa956d4c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = pd.concat([images.apply(reshape), flipped_images.apply(reshape)], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0612ccef-0737-4169-befc-b7f8ada9ac10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 256, 256)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "db95c7a7-34df-47f9-9f80-1606dee046fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4800, 3, 256, 256])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0cbe027f-340c-4bc7-b59c-6cb8ea4028c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_images = transforms(torch.tensor(fake_images.apply(reshape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ef1bec63-bf97-494b-9f59-02158505876e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4800, 3, 256, 256])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "24c06322-b88d-403a-a331-df3442bd6dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size = 24, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5e421976-d368-40c2-94dd-8e8f908e9d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_images_dataloader = torch.utils.data.DataLoader(fake_images, batch_size = 24, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "17320f5d-9999-4538-90e1-35bcca388e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0c49cf85-a262-4797-a28c-d47a67ae9d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "abb07c72-e8c9-48bc-aae2-bb7ffbc4dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32, momentum=0.78),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "89ed5238-12f3-4ec6-bbf1-9e2be02562f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Dropout(0.25),\n",
    "        nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "        nn.ZeroPad2d((0, 1, 0, 1)),\n",
    "        nn.BatchNorm2d(64, momentum=0.82),\n",
    "        nn.LeakyReLU(0.25),\n",
    "        nn.Dropout(0.25),\n",
    "        nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(128, momentum=0.82),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Dropout(0.25),\n",
    "        nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(256, momentum=0.8),\n",
    "        nn.LeakyReLU(0.25),\n",
    "        nn.Dropout(0.25),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(256 * 5 * 5, 1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "    def forward(self, img):\n",
    "        validity = self.model(img)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "59e87fac-1b1d-4fe1-8519-9f4f12e16879",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b95bff6c-44c4-45c8-995b-3d8060d31154",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(latent_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "optimizer_G = torch.optim.Adam(generator.parameters()\\\n",
    "                         , lr=lr, betas=(beta1, beta2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters()\\\n",
    "                         , lr=lr, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e4e39a53-d32e-41fe-9396-e10819e5fc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 3, 256, 256])\n",
      "torch.Size([3, 256, 256])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "unflatten: Provided sizes [128, 8, 8] don't multiply up to the size of dim 1 (256) in the input tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[196], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m optimizer_D\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     14\u001b[0m z \u001b[38;5;241m=\u001b[39m fake_images[i\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m24\u001b[39m]\n\u001b[1;32m---> 16\u001b[0m fake_paintings \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m real_loss \u001b[38;5;241m=\u001b[39m adversarial_loss(discriminator\\\n\u001b[0;32m     19\u001b[0m                              (real_paintings), valid)\n\u001b[0;32m     20\u001b[0m fake_loss \u001b[38;5;241m=\u001b[39m adversarial_loss(discriminator\\\n\u001b[0;32m     21\u001b[0m                              (fake_paintings\u001b[38;5;241m.\u001b[39mdetach()), fake)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[167], line 22\u001b[0m, in \u001b[0;36mGenerator.forward\u001b[1;34m(self, z)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, z):\n\u001b[1;32m---> 22\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03mRuns the forward pass.\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\flatten.py:164\u001b[0m, in \u001b[0;36mUnflatten.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m    Runs the forward pass.\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflattened_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:1418\u001b[0m, in \u001b[0;36mTensor.unflatten\u001b[1;34m(self, dim, sizes)\u001b[0m\n\u001b[0;32m   1416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39munflatten(dim, sizes, names)\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msizes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: unflatten: Provided sizes [128, 8, 8] don't multiply up to the size of dim 1 (256) in the input tensor"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        real_paintings = batch[0].to(device)\n",
    "        print(batch.shape)\n",
    "        print(real_paintings.shape)\n",
    "\n",
    "        valid = torch.ones(real_paintings.size(0), 1, device=device)\n",
    "        fake = torch.zeros(real_paintings.size(0), 1, device=device)\n",
    "\n",
    "        real_paintings = real_paintings.to(device)\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        z = fake_images[i*24]\n",
    "\n",
    "        fake_paintings = generator(z)\n",
    "\n",
    "        real_loss = adversarial_loss(discriminator\\\n",
    "                                     (real_paintings), valid)\n",
    "        fake_loss = adversarial_loss(discriminator\\\n",
    "                                     (fake_paintings.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        gen_images = generator(z)\n",
    "\n",
    "        g_loss = adversarial_loss(discriminator(gen_images), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch+1}/{num_epochs}]\\\n",
    "                        Batch {i+1}/{len(train_dataloader)} \"\n",
    "                f\"Discriminator Loss: {d_loss.item():.4f} \"\n",
    "                f\"Generator Loss: {g_loss.item():.4f}\"\n",
    "            )\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(16, latent_dim, device=device)\n",
    "            generated = generator(z).detach().cpu()\n",
    "            grid = torchvision.utils.make_grid(generated,\\\n",
    "                                        nrow=4, normalize=True)\n",
    "            plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d3037c-b444-41d9-8c0a-18b87e308792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
